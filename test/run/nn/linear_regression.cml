// linear_regression.cml - Linear Regression with Gradient Descent

module linear_regression

import {begin, enable, end, instant} from profiler

import {
    ones, zeros,
    sum, eye, transpose, show, pow, Tensor, shape, concat, range, to_float, random
} from tensor

// Mean Squared Error function
func mse_loss(predictions: Tensor, targets: Tensor): float sync {
    let errors = predictions - targets
    let squared_errors = pow(errors,2.0)
    let mse_tensor = sum(squared_errors)
    let sample_count = to_float(shape(predictions)[0])
    let mse = mse_tensor / sample_count
    return mse
}

// Linear regression using gradient descent
func train(X: Tensor, y: Tensor, learning_rate: float, num_iterations: int): Tensor sync {
    let m = shape(X)[0]  // number of samples
    let n = shape(X)[1]  // number of features
    
    let ones_col = ones([m, 1])
    println("Feature matrix X (4x2):")
    show(X)
    println("Bias column (4x1):")
    show(ones_col)
    let X_with_bias = concat(X, ones_col, 1)  // axis=1
    
    let weights_with_bias = zeros([n + 1, 1])
    
    println("Starting gradient descent...")

    func train_loop(i: int, weights: Tensor, X_bias: Tensor, targets: Tensor, sample_count: int, lr: float): Tensor sync {
        println(X)
        if (i >= num_iterations) then {
            return weights
        } 
        else sync {
            let predictions = X_bias @ weights
            
            let loss = mse_loss(predictions, targets)
            
            let errors = predictions - targets
            let dw = transpose(X_bias) @ errors
            dw = 2.0 / to_float(sample_count) * dw
            
            let new_weights = weights - lr * dw
            
            if (i % 100 == 0) then {
                let msg = "Iteration {}, Loss: {}"->format<i, loss>
                msg->println
            }
            
            return train_loop(i + 1, new_weights, X_bias, targets, sample_count, lr)
        }
    }
    
    let final_weights = train_loop(0, weights_with_bias, X_with_bias, y, m, learning_rate)
    println("Training completed.")
    return final_weights
}
// Predict function
func predict(X: Tensor, weights_with_bias: Tensor): Tensor sync {
    let m = shape(X)[0]
    let ones_col = ones([m, 1])
    let X_with_bias = concat(X, ones_col, 1)  // axis=1
    return X_with_bias @ weights_with_bias
}

func main(): int sync {
    println("=== Linear Regression with Gradient Descent ===")
    enable()
    begin()
    // Create training data (4 samples, 2 features)
    let X = random([4, 2],0.0,10.0)
    let y = ones([4, 1])
    
    println("Feature matrix X (4x2):")
    show(X)
    println("Target vector y (4x1):")
    show(y)
    
    // Train the model
    let learning_rate = 0.01
    let num_iterations = 100
    let trained_weights = train(X, y, learning_rate, num_iterations)
    instant()
    println("Trained weights (including bias):")
    show(trained_weights)
    
    // Make predictions
    let predictions = predict(X, trained_weights)
    println("Predictions:")
    show(predictions)
    
    // Calculate final loss
    let final_loss = mse_loss(predictions, y)
    let msg = "Final MSE Loss: {}"->format<final_loss>
    msg->println
    end()
    return 0
}